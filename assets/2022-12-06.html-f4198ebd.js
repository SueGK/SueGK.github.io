import{_ as o,Y as i,Z as l,$ as n,a0 as a,a1 as e,a2 as t,F as p}from"./framework-cef54de9.js";const c={},d=t(`<figure><img src="https://cdn-images-1.medium.com/max/3600/0*KGB2LDb3-ppXVajd" alt="by Sue" tabindex="0" loading="lazy"><figcaption>by Sue</figcaption></figure><h2 id="create-a-custom-dataset" tabindex="-1"><a class="header-anchor" href="#create-a-custom-dataset" aria-hidden="true">#</a> <strong>Create a custom dataset</strong></h2><p>To create a customized dataset in PyTorch, you should create a subclass of the torch.utils.data.Dataset class and implement the following methods:</p><ul><li><strong>init</strong>(): This method should initialize the dataset and any instance variables that you need. It should accept any arguments necessary to create the dataset.</li><li><strong>len</strong>(): This method should return the length of the dataset (i.e. the number of samples in the dataset).</li><li><strong>getitem</strong>(idx): This method should return the data for the sample with the specified index. The returned data should be a tuple containing the data and the corresponding label for the sample.</li></ul><p>Here is an example of how your custom dataset class might look:</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>    <span class="token keyword">import</span> torch
    <span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> Dataset

    <span class="token keyword">class</span> <span class="token class-name">CustomDataset</span><span class="token punctuation">(</span>Dataset<span class="token punctuation">)</span><span class="token punctuation">:</span>
        def__init__<span class="token punctuation">(</span>self<span class="token punctuation">,</span> data<span class="token punctuation">,</span> labels<span class="token punctuation">)</span><span class="token punctuation">:</span>
            self<span class="token punctuation">.</span>data <span class="token operator">=</span> data
            self<span class="token punctuation">.</span>labels <span class="token operator">=</span> labels

    def__len__<span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token keyword">return</span> <span class="token builtin">len</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>labels<span class="token punctuation">)</span>

    def__getitem__<span class="token punctuation">(</span>self<span class="token punctuation">,</span> idx<span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token keyword">return</span> self<span class="token punctuation">.</span>data<span class="token punctuation">[</span>idx<span class="token punctuation">]</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>labels<span class="token punctuation">[</span>idx<span class="token punctuation">]</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>To use your custom dataset, you can create an instance of the class and then pass it to a PyTorch DataLoader object. The DataLoader can then be used to iterate over the dataset and retrieve the samples.</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>    <span class="token comment"># Create an instance of the CustomDataset class</span>
    dataset <span class="token operator">=</span> CustomDataset<span class="token punctuation">(</span>data<span class="token punctuation">,</span> labels<span class="token punctuation">)</span>

    <span class="token comment"># Create a DataLoader for the dataset</span>
    dataloader <span class="token operator">=</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>dataset<span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

    <span class="token comment"># Loop over the dataloader to retrieve the samples</span>
    <span class="token keyword">for</span> data<span class="token punctuation">,</span> labels <span class="token keyword">in</span> dataloader<span class="token punctuation">:</span>
        <span class="token comment"># Do something with the data and labels</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div>`,8),r={href:"https://pytorch.org/docs/stable/data.html#creating-custom-datasets",target:"_blank",rel:"noopener noreferrer"},u=t(`<h2 id="what-does-dataloader-do" tabindex="-1"><a class="header-anchor" href="#what-does-dataloader-do" aria-hidden="true">#</a> <strong>what does dataloader do?</strong></h2><p>A PyTorch DataLoader is an object that provides a number of benefits when working with large datasets. It is typically used in conjunction with a Dataset object that provides the data that the DataLoader will iterate over.</p><p>The main purpose of the DataLoader is to batch the data from the Dataset and provide it to the model during training. It allows you to specify the batch size and whether or not the data should be shuffled each epoch. This can be useful for training models on large datasets that don&#39;t fit in memory, as it allows the data to be processed in smaller batches.</p><p>In addition to batching the data, the DataLoader can also be used to perform data augmentation and preprocessing on the fly. This can be useful for tasks like image classification, where you may want to apply random transformations to the images in each batch to improve the model&#39;s generalization ability.</p><p>Overall, the DataLoader is an important part of the PyTorch data processing pipeline, and is typically used when training deep learning models on large datasets. It provides an iterator over a dataset, allowing you to train your model on a large dataset by loading only a small portion of the data into memory at a time.</p><p>The DataLoader class takes a dataset and a batch size as input and returns an iterator over the dataset that yields mini-batches of data. You can use the DataLoader class to shuffle the data and define the number of workers that will be used to load the data in parallel.</p><p>One way to use the DataLoader class is with the for loop. Here is an example:</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>    <span class="token comment"># Import the DataLoader class</span>
    <span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> DataLoader

    <span class="token comment"># Create a dataset</span>
    dataset <span class="token operator">=</span> SomeDataset<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token comment"># Create a DataLoader instance</span>
    data_loader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>dataset<span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

    <span class="token comment"># Use the DataLoader object like an iterator</span>
    <span class="token keyword">for</span> data <span class="token keyword">in</span> data_loader<span class="token punctuation">:</span>
        <span class="token comment"># Get the data</span>
        inputs<span class="token punctuation">,</span> labels <span class="token operator">=</span> data

    <span class="token comment"># Use the data to train your model</span>
        train<span class="token punctuation">(</span>model<span class="token punctuation">,</span> inputs<span class="token punctuation">,</span> labels<span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>The DataLoader class also has a <strong>iter</strong> method that returns an iterator over the dataset, allowing you to use the DataLoader instance in a for loop.</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>    <span class="token comment"># Create a DataLoader instance</span>
    data_loader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>dataset<span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

    <span class="token comment"># Get an iterator over the dataset</span>
    data_iterator <span class="token operator">=</span> <span class="token builtin">iter</span><span class="token punctuation">(</span>data_loader<span class="token punctuation">)</span>

    <span class="token comment"># Use the iterator in a for loop</span>
    <span class="token keyword">for</span> data <span class="token keyword">in</span> data_iterator<span class="token punctuation">:</span>
        <span class="token comment"># Get the data</span>
        inputs<span class="token punctuation">,</span> labels <span class="token operator">=</span> data

    <span class="token comment"># Use the data to train your model</span>
        train<span class="token punctuation">(</span>model<span class="token punctuation">,</span> inputs<span class="token punctuation">,</span> labels<span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="collate-fn-in-dataloader" tabindex="-1"><a class="header-anchor" href="#collate-fn-in-dataloader" aria-hidden="true">#</a> <strong>collate_fn in DataLoader</strong></h2><p>The DataLoader class also provides a way to customize the way data is loaded by defining a collate_fn function. The collate_fn function defines how the data will be combined into a mini-batch. This is useful when your dataset contains data of different sizes, such as images of different sizes.</p><p>Here is an example of using a collate_fn function:</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>    <span class="token comment"># Import the DataLoader class</span>
    <span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> DataLoader

    <span class="token comment"># Create a dataset</span>
    dataset <span class="token operator">=</span> SomeDataset<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token comment"># Define a collate function</span>
    <span class="token keyword">def</span> <span class="token function">collate_fn</span><span class="token punctuation">(</span>data<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># Sort the data in descending order of length</span>
        data<span class="token punctuation">.</span>sort<span class="token punctuation">(</span>key<span class="token operator">=</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> <span class="token builtin">len</span><span class="token punctuation">(</span>x<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> reverse<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

    <span class="token comment"># Unpack the data</span>
        inputs<span class="token punctuation">,</span> labels <span class="token operator">=</span> <span class="token builtin">zip</span><span class="token punctuation">(</span><span class="token operator">*</span>data<span class="token punctuation">)</span>

    <span class="token comment"># Pad the inputs</span>
        inputs <span class="token operator">=</span> pad_sequence<span class="token punctuation">(</span>inputs<span class="token punctuation">,</span> batch_first<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

    <span class="token keyword">return</span> inputs<span class="token punctuation">,</span> labels

    <span class="token comment"># Create a DataLoader instance</span>
    data_loader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>dataset<span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span> collate_fn<span class="token operator">=</span>collate_fn<span class="token punctuation">)</span>

    <span class="token comment"># Use the DataLoader object like an iterator</span>
    <span class="token keyword">for</span> data <span class="token keyword">in</span> data_loader<span class="token punctuation">:</span>
        <span class="token comment"># Get the data</span>
        inputs<span class="token punctuation">,</span> labels <span class="token operator">=</span> data

    <span class="token comment"># Use the data to train your model</span>
        train<span class="token punctuation">(</span>model<span class="token punctuation">,</span> inputs<span class="token punctuation">,</span> labels<span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p><strong>Flowchat: How does DataLoader process data?</strong></p><figure><img src="https://cdn-images-1.medium.com/max/3600/0*KGB2LDb3-ppXVajd" alt="by Sue" tabindex="0" loading="lazy"><figcaption>by Sue</figcaption></figure><pre><code>num_dataset = 160
batch_size = 16
iteration = num_dataset / batch_size = 10 for i, data in enumerate(train_loader):
inputs, labels = data
</code></pre><p>When using a DataLoader instance in PyTorch, you can iterate over it in a for loop to retrieve the data in mini-batches.</p><p>In this example, the DataLoader instance will use a DataLoaderIter instance to load the data. The DataLoaderIter instance will call the Sampler to generate a list of indices that specify which elements from the dataset should be included in the mini-batch. The DataLoaderIter will then use a DatasetFetcher instance to retrieve the data from the dataset using the generated indices.</p><p>The DatasetFetcher instance will call the <strong>getitem</strong> method of the Dataset to retrieve the data for each index in the list of indices. This will return a list of data samples, where each sample is a tuple containing the input data and the corresponding label.</p><p>Finally, the DataLoaderIter will use the collate_fn function to combine the data samples into a mini-batch. The collate_fn function can be customized to define how the data will be combined into a mini-batch. The output of the collate_fn function is a mini-batch of data that is ready to be used by your model for training or evaluation.</p><p>In summary, when using a DataLoader instance in PyTorch,</p><ul><li>The resulting mini-batch of data is then yielded by the DataLoader instance in a for loop, and then decide whether to use a single or multi-process DataLoaderIter depending on whether multi-processing is used.</li><li>the data is loaded in mini-batches using a Sampler to generate indices</li><li>a DatasetFetcher to retrieve the data from the dataset based on the indices. In the DatasetFetcher, the <strong>getitem</strong>() method of the Dataset is called to get the real data. The data obtained here is a list, where each element is a tuple of (img, label)</li><li>a collate_fn function to combine the data into a mini-batch. So the data here is a list containing two elements, the tenser of img and label respectively.</li></ul>`,23),m={href:"https://twitter.com/Sue_sk79",target:"_blank",rel:"noopener noreferrer"};function h(k,v){const s=p("ExternalLinkIcon");return i(),l("div",null,[d,n("p",null,[a("You can learn more about creating custom datasets in PyTorch in the official PyTorch documentation: "),n("a",r,[a("https://pytorch.org/docs/stable/data.html#creating-custom-datasets"),e(s)])]),u,n("p",null,[a("Thank you for reading this post. If you enjoyed it, please consider following me on Medium and "),n("a",m,[a("twitter"),e(s)]),a(" for more content about productivity tools and AI! 🔥")])])}const f=o(c,[["render",h],["__file","2022-12-06.html.vue"]]);export{f as default};
