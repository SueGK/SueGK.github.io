<!DOCTYPE html>
<html lang="en-US" data-theme="light">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width,initial-scale=1" />
    <meta property="og:url" content="https://suegk.github.io/posts/2023-03-25.html"><meta property="og:site_name" content="Digest Today"><meta property="og:title" content="All you should know about translation equivariance/invariance in CNN"><meta property="og:description" content="All you should know about translation equivariance/invariance in CNN First published on Medium Translation invariance and translation equivariance are two important concepts in convolutional neural networks (CNNs) related to the network’s ability to recognise objects regardless of their position within an image."><meta property="og:type" content="article"><meta property="og:updated_time" content="2024-08-28T04:56:20.000Z"><meta property="og:locale" content="en-US"><meta property="article:tag" content="CNN"><meta property="article:published_time" content="2023-03-25T00:00:00.000Z"><meta property="article:modified_time" content="2024-08-28T04:56:20.000Z"><title>All you should know about translation equivariance/invariance in CNN | Digest Today</title><meta name="description" content="All you should know about translation equivariance/invariance in CNN First published on Medium Translation invariance and translation equivariance are two important concepts in convolutional neural networks (CNNs) related to the network’s ability to recognise objects regardless of their position within an image.">
    <meta name="keywords" content="自我提升,效率提升,开源工具,学习笔记" />
    <style>
      :root {
        --bg-color: #fff;
      }

      html[data-theme="dark"] {
        --bg-color: #1d2025;
      }

      html,
      body {
        background-color: var(--bg-color);
      }
    </style>
    <script>
      const userMode = localStorage.getItem("vuepress-theme-hope-scheme");
      const systemDarkMode =
        window.matchMedia &&
        window.matchMedia("(prefers-color-scheme: dark)").matches;

      if (userMode === "dark" || (userMode !== "light" && systemDarkMode)) {
        document.querySelector("html").setAttribute("data-theme", "dark");
      }
    </script>
    <link rel="preload" href="/assets/style-df4d757c.css" as="style"><link rel="stylesheet" href="/assets/style-df4d757c.css">
    <link rel="modulepreload" href="/assets/app-3941cd0f.js"><link rel="modulepreload" href="/assets/framework-cef54de9.js"><link rel="modulepreload" href="/assets/2023-03-25.html-84a41d08.js"><link rel="modulepreload" href="/assets/2023-03-25.html-1fc95240.js">
    <!-- 看板娘区块 -->
    <link href="https://lf9-cdn-tos.bytecdntp.com/cdn/expire-1-y/font-awesome/6.0.0/css/all.min.css" type="text/css" rel="stylesheet" />
    <script src="/live2d-widget/autoload.js"></script>
    <!-- End 看板娘区块 -->
    <!-- Matomo 此区块为统计代码，请删除-->
    <script>
      var _paq = window._paq = window._paq || [];
      /* tracker methods like "setCustomDimension" should be called before "trackPageView" */
      _paq.push(['trackPageView']);
      _paq.push(['enableLinkTracking']);
      (function() {
        var u="https://piwik.seoipo.com/";
        _paq.push(['setTrackerUrl', u+'matomo.php']);
        _paq.push(['setSiteId', '7']);
        var d=document, g=d.createElement('script'), s=d.getElementsByTagName('script')[0];
        g.async=true; g.src=u+'matomo.js'; s.parentNode.insertBefore(g,s);
      })();
    </script>
    <!-- End Matomo Code 此区块为统计代码，请删除-->
  </head>
  <body>
    <div id="app"><!--[--><!--[--><!--[--><span tabindex="-1"></span><a href="#main-content" class="skip-link sr-only">Skip to main content</a><!--]--><div class="theme-container has-toc"><!--[--><!--[--><header class="navbar"><div class="navbar-left"><button class="toggle-sidebar-button" title="Toggle Sidebar"><span class="icon"></span></button><!--[--><!----><!--]--><a href="/" class="brand"><img class="logo" src="/logo.svg" alt="Digest Today"><!----><span class="site-name hide-in-pad">Digest Today</span></a><!--[--><!----><!--]--></div><div class="navbar-center"><!--[--><!----><!--]--><nav class="nav-links"><div class="nav-item hide-in-mobile"><a href="/blog.html" class="nav-link" aria-label="博客"><span class="font-icon icon iconfont icon-blog" style=""></span>博客<!----></a></div><div class="nav-item hide-in-mobile"><a href="https://nav.newzone.top/" rel="noopener noreferrer" target="_blank" aria-label="工具收藏" class="nav-link"><span class="font-icon icon iconfont icon-tool" style=""></span>工具收藏<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span><!----></a></div></nav><!--[--><!----><!--]--></div><div class="navbar-right"><!--[--><!----><!--]--><div class="nav-item"><a class="repo-link" href="https://github.com/SueGK/SueGK.github.io" target="_blank" rel="noopener noreferrer" aria-label="GitHub"><svg xmlns="http://www.w3.org/2000/svg" class="icon github-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="github icon" style="width:1.25rem;height:1.25rem;vertical-align:middle;"><path d="M511.957 21.333C241.024 21.333 21.333 240.981 21.333 512c0 216.832 140.544 400.725 335.574 465.664 24.49 4.395 32.256-10.07 32.256-23.083 0-11.69.256-44.245 0-85.205-136.448 29.61-164.736-64.64-164.736-64.64-22.315-56.704-54.4-71.765-54.4-71.765-44.587-30.464 3.285-29.824 3.285-29.824 49.195 3.413 75.179 50.517 75.179 50.517 43.776 75.008 114.816 53.333 142.762 40.79 4.523-31.66 17.152-53.377 31.19-65.537-108.971-12.458-223.488-54.485-223.488-242.602 0-53.547 19.114-97.323 50.517-131.67-5.035-12.33-21.93-62.293 4.779-129.834 0 0 41.258-13.184 134.912 50.346a469.803 469.803 0 0 1 122.88-16.554c41.642.213 83.626 5.632 122.88 16.554 93.653-63.488 134.784-50.346 134.784-50.346 26.752 67.541 9.898 117.504 4.864 129.834 31.402 34.347 50.474 78.123 50.474 131.67 0 188.586-114.73 230.016-224.042 242.09 17.578 15.232 33.578 44.672 33.578 90.454v135.85c0 13.142 7.936 27.606 32.854 22.87C862.25 912.597 1002.667 728.747 1002.667 512c0-271.019-219.648-490.667-490.71-490.667z"></path></svg></a></div><div class="nav-item hide-in-mobile"><button class="outlook-button" tabindex="-1" ariahidden="true"><svg xmlns="http://www.w3.org/2000/svg" class="icon outlook-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="outlook icon"><path d="M224 800c0 9.6 3.2 44.8 6.4 54.4 6.4 48-48 76.8-48 76.8s80 41.6 147.2 0 134.4-134.4 38.4-195.2c-22.4-12.8-41.6-19.2-57.6-19.2C259.2 716.8 227.2 761.6 224 800zM560 675.2l-32 51.2c-51.2 51.2-83.2 32-83.2 32 25.6 67.2 0 112-12.8 128 25.6 6.4 51.2 9.6 80 9.6 54.4 0 102.4-9.6 150.4-32l0 0c3.2 0 3.2-3.2 3.2-3.2 22.4-16 12.8-35.2 6.4-44.8-9.6-12.8-12.8-25.6-12.8-41.6 0-54.4 60.8-99.2 137.6-99.2 6.4 0 12.8 0 22.4 0 12.8 0 38.4 9.6 48-25.6 0-3.2 0-3.2 3.2-6.4 0-3.2 3.2-6.4 3.2-6.4 6.4-16 6.4-16 6.4-19.2 9.6-35.2 16-73.6 16-115.2 0-105.6-41.6-198.4-108.8-268.8C704 396.8 560 675.2 560 675.2zM224 419.2c0-28.8 22.4-51.2 51.2-51.2 28.8 0 51.2 22.4 51.2 51.2 0 28.8-22.4 51.2-51.2 51.2C246.4 470.4 224 448 224 419.2zM320 284.8c0-22.4 19.2-41.6 41.6-41.6 22.4 0 41.6 19.2 41.6 41.6 0 22.4-19.2 41.6-41.6 41.6C339.2 326.4 320 307.2 320 284.8zM457.6 208c0-12.8 12.8-25.6 25.6-25.6 12.8 0 25.6 12.8 25.6 25.6 0 12.8-12.8 25.6-25.6 25.6C470.4 233.6 457.6 220.8 457.6 208zM128 505.6C128 592 153.6 672 201.6 736c28.8-60.8 112-60.8 124.8-60.8-16-51.2 16-99.2 16-99.2l316.8-422.4c-48-19.2-99.2-32-150.4-32C297.6 118.4 128 291.2 128 505.6zM764.8 86.4c-22.4 19.2-390.4 518.4-390.4 518.4-22.4 28.8-12.8 76.8 22.4 99.2l9.6 6.4c35.2 22.4 80 12.8 99.2-25.6 0 0 6.4-12.8 9.6-19.2 54.4-105.6 275.2-524.8 288-553.6 6.4-19.2-3.2-32-19.2-32C777.6 76.8 771.2 80 764.8 86.4z"></path></svg><div class="outlook-dropdown"><!----></div></button></div><div id="docsearch-container"></div><!--[--><!----><!--]--><button class="toggle-navbar-button" aria-label="Toggle Navbar" aria-expanded="false" aria-controls="nav-screen"><span class="button-container"><span class="button-top"></span><span class="button-middle"></span><span class="button-bottom"></span></span></button></div></header><!----><!--]--><!----><div class="toggle-sidebar-wrapper"><span class="arrow left"></span></div><aside class="sidebar"><!--[--><!----><!--]--><ul class="sidebar-links"><li><!--[--><a href="https://suegk.github.io/reading/" rel="noopener noreferrer" target="_blank" aria-label="Books&amp;Tutorials" class="nav-link sidebar-link sidebar-page"><span class="font-icon icon iconfont icon-read" style=""></span>Books&amp;Tutorials<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span><!----></a><ul class="sidebar-sub-headers"></ul><!--]--></li><li><section class="sidebar-group"><button class="sidebar-heading clickable"><!----><span class="title">🗳️ 自制流程图</span><span class="arrow right"></span></button><!----></section></li><li><section class="sidebar-group"><button class="sidebar-heading clickable"><!----><span class="title">🧩 Algorithms</span><span class="arrow right"></span></button><!----></section></li><li><section class="sidebar-group"><button class="sidebar-heading clickable"><!----><span class="title">🔗 MLOps</span><span class="arrow right"></span></button><!----></section></li><li><section class="sidebar-group"><button class="sidebar-heading clickable"><!----><span class="title">🔡 Code</span><span class="arrow right"></span></button><!----></section></li><li><section class="sidebar-group"><button class="sidebar-heading clickable"><!----><span class="title">🥑 Visualization</span><span class="arrow right"></span></button><!----></section></li><li><section class="sidebar-group"><button class="sidebar-heading clickable active"><span class="font-icon icon iconfont icon-blog" style=""></span><a href="/blog.html" class="title">Blog</a><span class="arrow down"></span></button><ul class="sidebar-links"><li><!--[--><a aria-current="page" href="/posts/2023-03-25.html" class="router-link-active router-link-exact-active nav-link active sidebar-link sidebar-page active" aria-label="All you should know about translation equivariance/invariance in CNN"><!---->All you should know about translation equivariance/invariance in CNN<!----></a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a aria-current="page" href="/posts/2023-03-25.html#all-you-should-know-about-translation-equivariance-invariance-in-cnn" class="router-link-active router-link-exact-active nav-link sidebar-link heading" aria-label="All you should know about translation equivariance/invariance in CNN"><!---->All you should know about translation equivariance/invariance in CNN<!----></a><ul class="sidebar-sub-headers"></ul></li><li class="sidebar-sub-header"><a aria-current="page" href="/posts/2023-03-25.html#translation-invariance" class="router-link-active router-link-exact-active nav-link sidebar-link heading" aria-label="Translation invariance"><!---->Translation invariance<!----></a><ul class="sidebar-sub-headers"></ul></li><li class="sidebar-sub-header"><a aria-current="page" href="/posts/2023-03-25.html#translation-equivariance" class="router-link-active router-link-exact-active nav-link sidebar-link heading" aria-label="Translation equivariance"><!---->Translation equivariance<!----></a><ul class="sidebar-sub-headers"></ul></li><li class="sidebar-sub-header"><a aria-current="page" href="/posts/2023-03-25.html#max-pooling-breaks-shift-equivariance-—-try-antialiaing" class="router-link-active router-link-exact-active nav-link sidebar-link heading" aria-label="Max Pooling breaks shift equivariance? — Try antialiaing"><!---->Max Pooling breaks shift equivariance? — Try antialiaing<!----></a><ul class="sidebar-sub-headers"></ul></li><li class="sidebar-sub-header"><a aria-current="page" href="/posts/2023-03-25.html#cnn-and-poorly-shift-invariant" class="router-link-active router-link-exact-active nav-link sidebar-link heading" aria-label="CNN and Poorly shift invariant"><!---->CNN and Poorly shift invariant<!----></a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a aria-current="page" href="/posts/2023-03-25.html#reference" class="router-link-active router-link-exact-active nav-link sidebar-link heading" aria-label="Reference"><!---->Reference<!----></a><ul class="sidebar-sub-headers"></ul></li></ul></li></ul><!--]--></li><li><!--[--><a href="/posts/2022-07-11.html" class="nav-link sidebar-link sidebar-page" aria-label="ML公式推导 — Logistic Regression Gradient Descent Derivatives"><!---->ML公式推导 — Logistic Regression Gradient Descent Derivatives<!----></a><ul class="sidebar-sub-headers"></ul><!--]--></li><li><!--[--><a href="/posts/2022-08-18.html" class="nav-link sidebar-link sidebar-page" aria-label="OpenCV-color in BGR order you must know"><!---->OpenCV-color in BGR order you must know<!----></a><ul class="sidebar-sub-headers"></ul><!--]--></li><li><!--[--><a href="/posts/2022-12-06.html" class="nav-link sidebar-link sidebar-page" aria-label="Pytorch DataLoader使用指南"><!---->Pytorch DataLoader使用指南<!----></a><ul class="sidebar-sub-headers"></ul><!--]--></li><li><!--[--><a href="/posts/2022-08-18-1.html" class="nav-link sidebar-link sidebar-page" aria-label="发现热门 ML/DL 研究论文的网站"><!---->发现热门 ML/DL 研究论文的网站<!----></a><ul class="sidebar-sub-headers"></ul><!--]--></li><li><!--[--><a href="/posts/2022-08-16.html" class="nav-link sidebar-link sidebar-page" aria-label="如何改变GitHub中照片的位置"><!---->如何改变GitHub中照片的位置<!----></a><ul class="sidebar-sub-headers"></ul><!--]--></li><li><!--[--><a href="/posts/2022-06-30.html" class="nav-link sidebar-link sidebar-page" aria-label="效率工具：Roam Research中Discourse Graph插件使用流程"><!---->效率工具：Roam Research中Discourse Graph插件使用流程<!----></a><ul class="sidebar-sub-headers"></ul><!--]--></li><li><!--[--><a href="/posts/2022-07-08.html" class="nav-link sidebar-link sidebar-page" aria-label="效率工具：Roam Research代办任务管理流程"><!---->效率工具：Roam Research代办任务管理流程<!----></a><ul class="sidebar-sub-headers"></ul><!--]--></li><li><!--[--><a href="/posts/2022-07-25.html" class="nav-link sidebar-link sidebar-page" aria-label="效率工具：书简管理器Raindrop"><!---->效率工具：书简管理器Raindrop<!----></a><ul class="sidebar-sub-headers"></ul><!--]--></li></ul></section></li></ul><!--[--><!----><!--]--></aside><!--[--><main class="page" id="main-content"><!--[--><!----><nav class="breadcrumb disable"></nav><div class="page-title"><h1><!---->All you should know about translation equivariance/invariance in CNN</h1><div class="page-info"><span class="category-info" aria-label="Category🌈" data-balloon-pos="down"><svg xmlns="http://www.w3.org/2000/svg" class="icon category-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="category icon"><path d="M148.41 106.992h282.176c22.263 0 40.31 18.048 40.31 40.31V429.48c0 22.263-18.047 40.31-40.31 40.31H148.41c-22.263 0-40.311-18.047-40.311-40.31V147.302c0-22.263 18.048-40.31 40.311-40.31zM147.556 553.478H429.73c22.263 0 40.311 18.048 40.311 40.31v282.176c0 22.263-18.048 40.312-40.31 40.312H147.555c-22.263 0-40.311-18.049-40.311-40.312V593.79c0-22.263 18.048-40.311 40.31-40.311zM593.927 106.992h282.176c22.263 0 40.31 18.048 40.31 40.31V429.48c0 22.263-18.047 40.31-40.31 40.31H593.927c-22.263 0-40.311-18.047-40.311-40.31V147.302c0-22.263 18.048-40.31 40.31-40.31zM730.22 920.502H623.926c-40.925 0-74.22-33.388-74.22-74.425V623.992c0-41.038 33.387-74.424 74.425-74.424h222.085c41.038 0 74.424 33.226 74.424 74.067v114.233c0 10.244-8.304 18.548-18.547 18.548s-18.548-8.304-18.548-18.548V623.635c0-20.388-16.746-36.974-37.33-36.974H624.13c-20.585 0-37.331 16.747-37.331 37.33v222.086c0 20.585 16.654 37.331 37.126 37.331H730.22c10.243 0 18.547 8.304 18.547 18.547 0 10.244-8.304 18.547-18.547 18.547z"></path></svg><span class="category-item category1 clickable" role="navigation">CV</span><meta property="articleSection" content="CV"></span><span class="tag-info" aria-label="Tag🏷" data-balloon-pos="down"><svg xmlns="http://www.w3.org/2000/svg" class="icon tag-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="tag icon"><path d="M939.902 458.563L910.17 144.567c-1.507-16.272-14.465-29.13-30.737-30.737L565.438 84.098h-.402c-3.215 0-5.726 1.005-7.634 2.913l-470.39 470.39a10.004 10.004 0 000 14.164l365.423 365.424c1.909 1.908 4.42 2.913 7.132 2.913s5.223-1.005 7.132-2.913l470.39-470.39c2.01-2.11 3.014-5.023 2.813-8.036zm-240.067-72.121c-35.458 0-64.286-28.828-64.286-64.286s28.828-64.285 64.286-64.285 64.286 28.828 64.286 64.285-28.829 64.286-64.286 64.286z"></path></svg><span class="tag-item tag-item0 clickable" role="navigation">CNN</span><meta property="keywords" content="CNN"></span><span class="words-info" aria-label="Words🔠" data-balloon-pos="down"><svg xmlns="http://www.w3.org/2000/svg" class="icon word-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="word icon"><path d="M518.217 432.64V73.143A73.143 73.143 0 01603.43 1.097a512 512 0 01419.474 419.474 73.143 73.143 0 01-72.046 85.212H591.36a73.143 73.143 0 01-73.143-73.143z"></path><path d="M493.714 566.857h340.297a73.143 73.143 0 0173.143 85.577A457.143 457.143 0 11371.566 117.76a73.143 73.143 0 0185.577 73.143v339.383a36.571 36.571 0 0036.571 36.571z"></path></svg><span>About 1240 words</span><meta property="wordCount" content="1240"></span><span class="reading-time-info" aria-label="Reading Time⌛" data-balloon-pos="down"><svg xmlns="http://www.w3.org/2000/svg" class="icon timer-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="timer icon"><path d="M799.387 122.15c4.402-2.978 7.38-7.897 7.38-13.463v-1.165c0-8.933-7.38-16.312-16.312-16.312H256.33c-8.933 0-16.311 7.38-16.311 16.312v1.165c0 5.825 2.977 10.874 7.637 13.592 4.143 194.44 97.22 354.963 220.201 392.763-122.204 37.542-214.893 196.511-220.2 389.397-4.661 5.049-7.638 11.651-7.638 19.03v5.825h566.49v-5.825c0-7.379-2.849-13.981-7.509-18.9-5.049-193.016-97.867-351.985-220.2-389.527 123.24-37.67 216.446-198.453 220.588-392.892zM531.16 450.445v352.632c117.674 1.553 211.787 40.778 211.787 88.676H304.097c0-48.286 95.149-87.382 213.728-88.676V450.445c-93.077-3.107-167.901-81.297-167.901-177.093 0-8.803 6.99-15.793 15.793-15.793 8.803 0 15.794 6.99 15.794 15.793 0 80.261 63.69 145.635 142.01 145.635s142.011-65.374 142.011-145.635c0-8.803 6.99-15.793 15.794-15.793s15.793 6.99 15.793 15.793c0 95.019-73.789 172.82-165.96 177.093z"></path></svg><span>About 4 min</span><meta property="timeRequired" content="PT4M"></span><!----></div><hr></div><div class="toc-place-holder"><aside id="toc"><div class="toc-header">On This Page</div><div class="toc-wrapper"><ul class="toc-list"><!--[--><li class="toc-item"><a aria-current="page" href="/posts/2023-03-25.html#all-you-should-know-about-translation-equivariance-invariance-in-cnn" class="router-link-active router-link-exact-active toc-link level2">All you should know about translation equivariance/invariance in CNN</a></li><!----><!--]--><!--[--><li class="toc-item"><a aria-current="page" href="/posts/2023-03-25.html#translation-invariance" class="router-link-active router-link-exact-active toc-link level2">Translation invariance</a></li><!----><!--]--><!--[--><li class="toc-item"><a aria-current="page" href="/posts/2023-03-25.html#translation-equivariance" class="router-link-active router-link-exact-active toc-link level2">Translation equivariance</a></li><!----><!--]--><!--[--><li class="toc-item"><a aria-current="page" href="/posts/2023-03-25.html#max-pooling-breaks-shift-equivariance-—-try-antialiaing" class="router-link-active router-link-exact-active toc-link level2">Max Pooling breaks shift equivariance? — Try antialiaing</a></li><!----><!--]--><!--[--><li class="toc-item"><a aria-current="page" href="/posts/2023-03-25.html#cnn-and-poorly-shift-invariant" class="router-link-active router-link-exact-active toc-link level2">CNN and Poorly shift invariant</a></li><ul class="toc-list"><!--[--><li class="toc-item"><a aria-current="page" href="/posts/2023-03-25.html#reference" class="router-link-active router-link-exact-active toc-link level3">Reference</a></li><!----><!--]--></ul><!--]--></ul></div></aside></div><!----><div class="theme-hope-content"><h2 id="all-you-should-know-about-translation-equivariance-invariance-in-cnn" tabindex="-1"><a class="header-anchor" href="#all-you-should-know-about-translation-equivariance-invariance-in-cnn" aria-hidden="true">#</a> All you should know about translation equivariance/invariance in CNN</h2><p>First published on <a href="https://medium.com/@sue.sk.guo/all-you-should-know-about-translation-equivariance-invariance-in-cnn-cbf2a2ad33cd" target="_blank" rel="noopener noreferrer">Medium<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></p><p>Translation invariance and translation equivariance are two important concepts in convolutional neural networks (CNNs) related to the network’s ability to recognise objects regardless of their position within an image.</p><figure><img src="https://cdn-images-1.medium.com/max/2394/1*hF9FN5Ruac76-s5zcfZ0tQ.png" alt="05 Imperial’s Deep learning course: Equivariance and Invariance — YouTube" tabindex="0" loading="lazy"><figcaption>05 Imperial’s Deep learning course: Equivariance and Invariance — YouTube</figcaption></figure><h2 id="translation-invariance" tabindex="-1"><a class="header-anchor" href="#translation-invariance" aria-hidden="true">#</a> Translation invariance</h2><figure><img src="https://cdn-images-1.medium.com/max/2092/0*yddB6NGhDosJmw-q" alt="05 Imperial’s Deep learning course: Equivariance and Invariance — YouTube" tabindex="0" loading="lazy"><figcaption>05 Imperial’s Deep learning course: Equivariance and Invariance — YouTube</figcaption></figure><figure><img src="https://cdn-images-1.medium.com/max/2000/1*uZ8kByev1Lc5oiDh2jxr7Q.gif" alt="05 Imperial’s Deep learning course: Equivariance and Invariance — YouTube" tabindex="0" loading="lazy"><figcaption>05 Imperial’s Deep learning course: Equivariance and Invariance — YouTube</figcaption></figure><p><strong>Translation invariance</strong> means that a CNN is able to recognise an object in an image regardless of its location or translation within the image. In other words, the network’s output should remain the same even if the image is shifted or translated in any direction. This property is desirable because it allows the network to generalize well to different images of the same object with different translations.</p><p><strong>Summary:</strong></p><ul><li>Pooling layers help build shift invariance in convolutional networks.</li><li>Shift invariance means that the same maximum value will be found under the pooling kernel even if the image is shifted slightly.</li><li>However, this shift invariance is only locally true and may not hold if the image is shifted too much.</li><li>Pooling is not completely bulletproof with regards to shift invariance, but it can still identify the same features in an image regardless of their position.</li></ul><h2 id="translation-equivariance" tabindex="-1"><a class="header-anchor" href="#translation-equivariance" aria-hidden="true">#</a> Translation equivariance</h2><figure><img src="https://cdn-images-1.medium.com/max/2128/0*emgASPn__BRxHofS" alt="05 Imperial’s Deep learning course: Equivariance and Invariance — YouTube" tabindex="0" loading="lazy"><figcaption>05 Imperial’s Deep learning course: Equivariance and Invariance — YouTube</figcaption></figure><p>Translation equivariance, on the other hand, means that the network’s output is related to the location of the object within the image. More specifically, if the input image is shifted or translated, the output of the network will also be shifted or translated accordingly. This property is useful for tasks such as object detection, where the location of the object within the image is important.</p><p>In CNNs, translation invariance is achieved through the use of pooling layers, which aggregate <strong>feature maps</strong> into a more compact representation while preserving the most important features. Meanwhile, translation equivariance is achieved through the use of convolutional layers, which apply a filter or kernel to the input image to <strong>extract local features</strong> that are then combined to form a larger, more complex feature map. By using a combination of convolutional and pooling layers, CNNs are able to achieve both translation invariance and equivariance, making them highly effective for image recognition tasks.</p><h2 id="max-pooling-breaks-shift-equivariance-—-try-antialiaing" tabindex="-1"><a class="header-anchor" href="#max-pooling-breaks-shift-equivariance-—-try-antialiaing" aria-hidden="true">#</a> Max Pooling breaks shift equivariance? — Try antialiaing</h2><figure><img src="https://cdn-images-1.medium.com/max/2000/0*Wyy2QtclkDCkUXbA.gif" alt="Making Convolutional Networks Shift-Invariant Again" tabindex="0" loading="lazy"><figcaption>Making Convolutional Networks Shift-Invariant Again</figcaption></figure><p>Convolutional neural networks (CNNs) are approximately shift equivalent through their convolutional layers. However, the use of Max Pooling layers can break shift equivariance (also known as translation equivariance). To address this issue, one solution is to use anti-aliasing techniques in Computer Vision, such as blurring the image and then down-sampling it. This technique can help preserve important features in the image while reducing the effect of minor shifts or translations, which in turn can improve the shift equivariance of the CNN.</p><p>You can check more in the <a href="https://richzhang.github.io/antialiased-cnns/" target="_blank" rel="noopener noreferrer">paper<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></p><figure><img src="https://cdn-images-1.medium.com/max/2000/1*unim0oPZtXDmRnWSXz4cyQ.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>There is another research about <a href="http://visual.cs.ucl.ac.uk/pubs/harmonicNets/index.html" target="_blank" rel="noopener noreferrer">Harmonic Networks: Deep Translation and Rotation Equivariance<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></p><figure><img src="https://cdn-images-1.medium.com/max/2000/1*wIjQ3UY25Tk6BqHiI_1jZg.gif" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><h2 id="cnn-and-poorly-shift-invariant" tabindex="-1"><a class="header-anchor" href="#cnn-and-poorly-shift-invariant" aria-hidden="true">#</a> CNN and Poorly shift invariant</h2><p><a href="https://arxiv.org/abs/1805.12177" target="_blank" rel="noopener noreferrer">Why do deep convolutional networks generalize so poorly to small image transformations?<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></p><blockquote><p>Convolutional Neural Networks (CNNs) are commonly assumed to be invariant to small image transformations: either because of the convolutional architecture or because they were trained using data augmentation. Recently, several authors have shown that this is not the case: small translations or rescalings of the input image can drastically change the network’s prediction. In this paper, we quantify this phenomena and ask why neither the convolutional architecture nor data augmentation are sufficient to achieve the desired invariance. Specifically, we show that</p><ul><li>the convolutional architecture does not give invariance since architectures ignore the classical sampling theorem,</li><li>and data augmentation does not give invariance because the CNNs learn to be invariant to transformations only for images that are very similar to typical images from the training set. We discuss two possible solutions to this problem: (1) antialiasing the intermediate representations and (2) increasing data augmentation and show that they provide only a partial solution at best. Taken together, our results indicate that the problem of insuring invariance to small image transformations in neural networks while preserving high accuracy remains unsolved.</li></ul></blockquote><p>There are also some interesting opinions from (Chinese Platform)</p><p><a href="https://www.zhihu.com/question/301522740/answer/531606623" target="_blank" rel="noopener noreferrer">Since CNN has translation invariance to images, will it be effective to use image translation (shift) for data augmentation to train CNN?<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></p><ul><li>It is precisely because pooling itself has weak translation invariance and will lose some information that in tasks that require translation equivariance (such as detection and segmentation), convolutional layers with a stride of 2 are often used instead of pooling layers.</li><li>In many classification tasks, global pooling or pyramid pooling is often used at the end of the network to learn global features.</li><li>The translation invariance that can be used for classification mainly comes from the parameters. Because of the translation equivalence of convolutional layers, this kind of translation invariance is mainly learned by the final fully connected layer, and it is more difficult for networks without fully connected layers to have this property.</li><li>To summarize, the translation invariance of CNN mainly comes from data learning, and the structure can only bring very weak translation invariance, while learning relies on data augmentation.</li></ul><h3 id="reference" tabindex="-1"><a class="header-anchor" href="#reference" aria-hidden="true">#</a> Reference</h3><ul><li><a href="https://www.youtube.com/watch?v=a4Quhf9NhMY&amp;t=944s" target="_blank" rel="noopener noreferrer">05 Imperial’s Deep learning course: Equivariance and Invariance — YouTube<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></li><li><a href="https://chriswolfvision.medium.com/what-is-translation-equivariance-and-why-do-we-use-convolutions-to-get-it-6f18139d4c59" target="_blank" rel="noopener noreferrer">What is translation equivariance, and why do we use convolutions to get it? | by Christian Wolf | Medium<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></li><li><a href="https://richzhang.github.io/antialiased-cnns/" target="_blank" rel="noopener noreferrer">Making Convolutional Networks Shift-Invariant Again<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></li><li><a href="http://visual.cs.ucl.ac.uk/pubs/harmonicNets/index.html" target="_blank" rel="noopener noreferrer">Harmonic Networks: Deep Translation and Rotation Equivariance<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></li><li><a href="https://www.zhihu.com/question/301522740/answer/531606623" target="_blank" rel="noopener noreferrer">Since CNN has translation invariance to images, will it be effective to use image translation (shift) for data augmentation to train CNN?<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></li></ul></div><!----><footer class="page-meta"><div class="meta-item edit-link"><a href="https://github.com/SueGK/SueGK.github.io/edit/main/docs/_posts/2023-03-25.md" rel="noopener noreferrer" target="_blank" aria-label="Edit this page" class="nav-link label"><!--[--><svg xmlns="http://www.w3.org/2000/svg" class="icon edit-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="edit icon"><path d="M430.818 653.65a60.46 60.46 0 0 1-50.96-93.281l71.69-114.012 7.773-10.365L816.038 80.138A60.46 60.46 0 0 1 859.225 62a60.46 60.46 0 0 1 43.186 18.138l43.186 43.186a60.46 60.46 0 0 1 0 86.373L588.879 565.55l-8.637 8.637-117.466 68.234a60.46 60.46 0 0 1-31.958 11.229z"></path><path d="M728.802 962H252.891A190.883 190.883 0 0 1 62.008 771.98V296.934a190.883 190.883 0 0 1 190.883-192.61h267.754a60.46 60.46 0 0 1 0 120.92H252.891a69.962 69.962 0 0 0-69.098 69.099V771.98a69.962 69.962 0 0 0 69.098 69.098h475.911A69.962 69.962 0 0 0 797.9 771.98V503.363a60.46 60.46 0 1 1 120.922 0V771.98A190.883 190.883 0 0 1 728.802 962z"></path></svg><!--]-->Edit this page<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span><!----></a></div><div class="meta-item update-time"><span class="label">Last update: </span><!----></div><!----></footer><nav class="page-nav"><!----><a href="/posts/2022-07-11.html" class="nav-link next" aria-label="ML公式推导 — Logistic Regression Gradient Descent Derivatives"><div class="hint">Next<span class="arrow right"></span></div><div class="link">ML公式推导 — Logistic Regression Gradient Descent Derivatives<!----></div></a></nav><div class="giscus-wrapper input-top" style="display:block;"><div style="text-align:center">Loading...</div></div><!----><!--]--></main><!--]--><!----><!--]--></div><!--]--><!----><!----><!--]--></div>
    <script type="module" src="/assets/app-3941cd0f.js" defer></script>
  </body>
</html>
